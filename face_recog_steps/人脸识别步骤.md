## 举例

​	给计算机输入一套房的面积，位置，朝向，房间数目，计算机就可以自动给你算出它的**价格**（回归算法）；输入一个人的学历，住址，朋友数目，去过的地方，计算机也可以自动给你算出他／她的**年收入**(回归算法)；输入一种植物的花瓣数目，花瓣宽度／长度，叶子长度/宽度，花香描述等，计算机就可以告诉我们这种植物的**名称**(分类算法)；......

​	这些问题都可以通过选择一个机器学习算法,给它数据,然后等待输出结果.　人脸识别也是可以通过机器学习算法来做的，但人脸识别(face recognition)是由一系列机器学习算法构成的．(显示同一个名人的三张照片)

1. 在图上找出所有的人脸．

2.  对同一张脸，即使它旋转或者扭曲，让计算机要能知道这是同样一张脸．

3.  能找出这张脸独特的特征，以用来将这张脸与其他人的脸区分开（特征可以是：眼睛大小，鼻子长度等）.

4. 将该脸的独特特征与所有已经标识的人脸进行对照,以确定该人脸对应的人的姓名.


​	注意：我们的大脑能瞬间完成上面所有的步骤！我们的大脑非常善于人脸识别！

## 人脸识别步骤

​	我们分四个步骤来处理人脸识别. 

​	对每一步, 我们将学习一个不同的机器学习算法．我们将会学习每一个算法背后的基本思想．以后你可以用Python去建立自己的人脸识别系统．可能用到的库有OpenFace和dlib.

### 第一步: 找出所有的人脸　

​	第一步是人脸探测. 区分人脸之前，首先要找出人脸在照片中的位置!

近几年来的相机都有人脸探测的功能，它能找出人脸，以便可以对每张人脸对焦，从而得出更清晰的照片．

而我们这里用来做识别人脸，而非得到更清晰的照片．

​	注：自从Paul Viola和Michael Jones 发明了能应用在一般照相机上的快速探测人脸的方法，人脸探测在上个时代初就成为主流技术．但现在，人们有了更好的方法用于快速探测人脸． 

​	我们将用的方法----方向梯度直方图(Histogram of Oriented Gradients, HOG, 2005).　首先将照片转成黑白照片,因为色彩的信息我们不需要．然后，我们依次关注照片中的每一个像素点． 对每个像素点,　我们想看看那些直接包围着它的像素点. 我们的目标：计算出当前像素相对于其周围的像素有多暗. 然后我们想画出像素由明到暗变化最快的方向:

<img src="https://github.com/hg08/tututu/blob/master/oriented_gradients.gif?raw=true">



对照片中的**每一个像素点**重复上述操作, 最终每一个像素都被一个箭头取代了. 这些箭头称为**梯度** ,它们显示整张照片由明到暗变化最快的方向．

这样做有什么好处？ 如果我们直接分析像素, 同一个人的非常暗的照片和非常亮的照片将具有完全不同的像素值. 但是考虑亮度改变的**方向**时，暗照片和两照片将有几乎一样的表示!

进一步简化：我们用梯度来看一些基本模式，而不是所有细节！为了达到这目的，我们将照片分成小方格，每个方格的大小为16x16像素． 在每一个小方格中,我们将计算在每个主要方向有多少个梯度点 (有多少个指向上方，有多少个指向下方，有多少个指向右上方，等等). 然后我们以最强的箭头方向去取代该小方格．　这样，我们将原图片转化成了非常简单的表示．它只以简单的方式描述人脸的基本结构:

<img src="https://github.com/hg08/tututu/blob/master/basic_structure_of_face.png?raw=true" width="400">

为了在这张HOG图片中找到人脸, 我们只需找到我们的图片中最像**已知HOG 模式**的那部分．已知HOG模式由大量其他照片训练并提取出来，如图：

<img src="https://github.com/hg08/tututu/blob/master/HOG_face_pattern_standard.png?raw=true">



具体组成部分：运用Dlib库中的face detection algorithm 来看是否图片中有人脸存在. 如果有, 这算法会为每一张脸创建一个 "end position".

## 第二步: 人脸标记和变换

​	基本思想：我们将选出每张人脸上的68个特殊点 (*地标*) ----如眼睛的外边界, 眉毛的内边界,等. 然后我们将运用一个机器学习算法在任意一张人脸上找出这些特殊点:

​	当我们知道人脸的双眼和嘴的位置，我们将简单地旋转,伸缩和剪切(shear)这张图片，使得双眼和嘴尽可能地centered. 我们将不会做任何３维 warps以免引入照片的畸变. 我们只运用基本的图形变换，如保持平行线仍然平行的旋转变换和伸缩变换 (仿射变换(affine transformations))．

​	注：现在无论人脸如何转动, 我们都能将眼睛和嘴基本上置于照片中心相同的位置. 这将使我们下一步更精确.



## 第三步: 编码

​	现在开始区分不同的人脸!	最简单的人脸识别方法是直接将第二步中找出的未知人脸与我们已经带有标识的所有照片进行对照. 当我们发现一张已带有标签的人脸与未知人脸非常相似时,那它们一定是同一个人的脸. 这个想法有趣吧？

​	这个方法还有一个问题. 具有上亿用户和照片的网站不可能遍历每一张有标签的人脸来与新上传的照片进行对比.　那样太耗时.　人脸识别应该在数毫秒内完成．

​	我们需要的是一种用于提取每一张人脸的几个基本测量值的方法．然后我们可以以同样的方式测量新的人脸照片，并找出与之有最接近的测量值的已知人脸.　例如，我们可能测量每一只耳朵的尺寸,两眼间距, 鼻子长度等. 



### 测量人脸的最可靠方法

 我们应该从每一张脸上收集哪些测量值来建立我们的＂熟人＂数据库呢？　耳朵大小？眉毛长度?　眼睛大小？鼻子宽度？　人们发现，最精确的方法是**让计算机自己去决定该收集哪些测量值**．对于人脸的哪部分对测量而言最重要这一问题，深度学习算法比人类做得更好!　具体的解决办法是训练一个深度卷积神经网络, 并训练它对每张人脸产生128个测量值.

$$
2^7 = 128
$$

### 训练过程的工作方式

训练过程通过同时看３张人脸图片来工作：

1. 加载一个熟人的训练人脸照片(左)；
2. 加载同一个熟人的另一张照片(中)；
3. 加载另外一个人的一张照片(右)．


然后这个算法looks at这些三张照片中在当前产生的各自测量值. 然后，算法轻微地调整神经网络以确保照片1和照片2的测量值微微接近，而使得照片２和照片3的测量值微微远离:

<img src="https://github.com/hg08/face_recog_lecture/blob/master/knn_examples/train/WuYifan/wu1.jpg?raw=true" width="225"> <img src="https://github.com/hg08/face_recog_lecture/blob/master/knn_examples/train/WuYifan/wu2.png?raw=true" width="160">   <img src="https://github.com/hg08/face_recog_lecture/blob/master/knn_examples/test/li1.png?raw=true" width="185">

　　　　　照片１　　　　　　　　　照片２　　　　　　　　　照片３　　　　　　　　　

对数千人的数百万张照片重复这个过程数百万次,这个神经网络学会了可靠地对每一个人产生这128个测量值. 同一个人的任意数十张不同照片将会给出基本相同的测量值! 在机器学习领域，人们称每张人脸中的这128个测量值为 一个＂嵌入＂(embedding).  将图片这样的复杂数据简化为数字的列表这样的思想在机器学习领域常常出现．我们这里用的方法是2015年谷歌的研究人员发明的. 相似的方法还有很多.

### 为人脸编码

​	训练神经网络非常耗时，即使你有大型计算机．但是一旦神经网络训练完成，它便可以对任意一张从未见过的人脸产生出测量值．所以，训练只需要运行一次！  OpenFace的研究人员已经训练除了一些神经网络，我们可以直接使用 (参考Brandon Amos and team)! 我们需要亲自做的就是：使我们的人脸照片输入至他们已经训练好的神经网络中以得到那128个测量值. (measurements for our test image示例:)

如果想问这128个数值分别测量的是什么呢? 答案是我们不知道！我们关注的是这个网络在看同一个人的两张不同的照片时，产出出几乎一样的数.

​	注:If you want to try this step yourself, OpenFace provides a lua script that will generate embeddings all images in a folder and write them to a csv file (Comma-separated values). You run it like this.

## 第四步: 由编码找出人名

最后一步！我们只需在已标识的＂熟人＂数据集里，找出那个与测试照片中的人脸距离最近的人.

方法：任意基本的机器学习分类算法．无需深度学习算法．可以运用**线性SVM分类器**,　注意很多其他分类器也可以.

我们只需训练一个分类器 来测量新的测试照片，并给出哪一个认识的人与测试照片中人脸的距离最近． 运行这个分类器只花费几毫秒.　这个分类器的结果是这个人的名字． 

So let’s try out our system. First, I trained a classifier with the embeddings of about 20 pictures each of Will Ferrell, Chad Smith and Jimmy Falon:

接下来，我运行分类器于Will Ferrell 和Chad Smith视频的每一帧，他们在Jimmy Fallon的电视节目上乔装成对方:

## 运行

概述我们的步骤:

运用HOG算法进行编码，以创建图片的简化版.

运用此简化图片,找出照片中最像一般的人脸HOG编码的部分.
通过找出人脸中主要的landmarks,计算出该人脸的pose.

一旦我们发现这些landmarks, 运用它们来warp该简化图片以使得双眼和嘴是centered.
输入该centered 人脸图片给一个神经网络，该神经网络知道如何测量该脸的特征. 保存这128个测量值.
观察我们过去已经测量过的所有人脸, 看哪一个人具有与我们当前人脸的测量值最接近的测量值. 找到该人脸，则匹配成功!



## 参考：

1. Adam Geitgey, Machine Learning is Fun!  Part 4: Modern Face Recognition with Deep Learning


2. Eorror: 

		ModuleNotFoundError: No module named 'cv2'

​       Solution:

	conda install -c conda-forge opencv
	conda install -c conda-forge/label/broken opencv
